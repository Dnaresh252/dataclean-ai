{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9620428c-dbea-4c7d-8a53-e8b3327349aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create Feature Dataset for ML Training\n",
    "======================================\n",
    "\n",
    "Process:\n",
    "1. Load all synthetic messy files\n",
    "2. For each file, extract features from every column\n",
    "3. Combine with labels (what problems exist)\n",
    "4. Save as final training dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../ml_pipeline')\n",
    "\n",
    "from data.feature_extractor import ColumnFeatureExtractor\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc37ac2-83ef-4769-8645-e761348df861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 messy files\n",
      "  - messy_001_titanic_v0.csv\n",
      "  - messy_002_titanic_v1.csv\n",
      "  - messy_003_titanic_v2.csv\n",
      "  - messy_004_tips_v0.csv\n",
      "  - messy_005_tips_v1.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load all generated messy CSV files\n",
    "\"\"\"\n",
    "\n",
    "messy_files = list(Path('../data/synthetic/messy').glob('*.csv'))\n",
    "print(f\"Found {len(messy_files)} messy files\")\n",
    "\n",
    "# Show first few\n",
    "for f in messy_files[:5]:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668ebe14-675f-4db1-854f-28b0aae2f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extracted features from 129 columns\n",
      "‚úÖ Labels generated from ACTUAL column data (not file labels)\n",
      "‚úÖ Thresholds: duplicates>50%, missing>5%, outliers>3%, format<80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For each file, extract features from each column\n",
    "This will take a few minutes...\n",
    "\n",
    "FIX: Generate column-specific labels based on ACTUAL column data,\n",
    "not file-level labels!\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for messy_file in tqdm(messy_files, desc=\"Processing files\"):\n",
    "    # Load messy CSV\n",
    "    df = pd.read_csv(messy_file)\n",
    "    \n",
    "    # Extract features from each column\n",
    "    for col in df.columns:\n",
    "        extractor = ColumnFeatureExtractor(df[col], col)\n",
    "        features = extractor.extract_all_features()\n",
    "        \n",
    "        # Add file metadata\n",
    "        features['filename'] = messy_file.name\n",
    "        features['column_name'] = col\n",
    "        \n",
    "        # ========================================\n",
    "        # COLUMN-LEVEL LABELING (FIXED!)\n",
    "        # ========================================\n",
    "        # Check THIS column's actual characteristics\n",
    "        # Not the file-level labels!\n",
    "        \n",
    "        # Label 1: Has duplicates?\n",
    "        # Higher threshold - only flag if >50% are duplicates\n",
    "        features['has_duplicates'] = 1 if features['duplicate_percentage'] > 50 else 0\n",
    "        \n",
    "        # Label 2: Has missing values?\n",
    "        # If >5% of values are missing, mark as 1\n",
    "        features['has_missing'] = 1 if features['missing_percentage'] > 5 else 0\n",
    "        \n",
    "        # Label 3: Has outliers?\n",
    "        # If >3% of values are outliers, mark as 1\n",
    "        features['has_outliers'] = 1 if features['outlier_percentage'] > 3 else 0\n",
    "        \n",
    "        # Label 4: Has format issues?\n",
    "        # If format consistency < 80%, mark as 1\n",
    "        features['has_format_issue'] = 1 if features['format_consistency_score'] < 80 else 0\n",
    "        \n",
    "        # Label 5: Has type issues?\n",
    "        # Check if numeric column was converted to string\n",
    "        # Or if cardinality suggests it should be numeric but it's object\n",
    "        is_object_but_should_be_numeric = (features['dtype_object'] == 1 and \n",
    "                                           features['contains_digits_pct'] > 80)\n",
    "        features['has_type_issue'] = 1 if is_object_but_should_be_numeric else 0\n",
    "        \n",
    "        all_features.append(features)\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted features from {len(all_features)} columns\")\n",
    "print(\"‚úÖ Labels generated from ACTUAL column data (not file labels)\")\n",
    "print(\"‚úÖ Thresholds: duplicates>50%, missing>5%, outliers>3%, format<80%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a3b165-5a9a-4c4f-9383-4a96d206f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dataset shape: (129, 40)\n",
      "\n",
      "Columns:\n",
      "['total_rows', 'missing_count', 'missing_percentage', 'unique_count', 'cardinality', 'duplicate_count', 'duplicate_percentage', 'mean', 'median', 'std', 'min', 'max', 'range', 'outlier_count', 'outlier_percentage', 'skewness', 'avg_length', 'length_std', 'contains_digits_pct', 'contains_special_pct', 'all_uppercase_pct', 'all_lowercase_pct', 'format_consistency_score', 'name_contains_id', 'name_contains_name', 'name_contains_email', 'name_contains_phone', 'name_contains_date', 'name_contains_amount', 'dtype_numeric', 'dtype_object', 'dtype_datetime', 'dtype_bool', 'filename', 'column_name', 'has_duplicates', 'has_missing', 'has_outliers', 'has_format_issue', 'has_type_issue']\n",
      "\n",
      "First few rows:\n",
      "   total_rows  missing_count  missing_percentage  unique_count  cardinality  \\\n",
      "0         980            136           13.877551             5     0.005102   \n",
      "1         980            157           16.020408             6     0.006122   \n",
      "2         980            158           16.122449             8     0.008163   \n",
      "3         980            308           31.428571            85     0.086735   \n",
      "4         980            155           15.816327             7     0.007143   \n",
      "\n",
      "   duplicate_count  duplicate_percentage       mean  median        std  ...  \\\n",
      "0              974             99.387755   0.445838     0.0   1.256866  ...   \n",
      "1              973             99.285714   2.843169     3.0  10.855669  ...   \n",
      "2              971             99.081633   0.000000     0.0   0.000000  ...   \n",
      "3              894             91.224490  29.774182    28.0  14.504112  ...   \n",
      "4              972             99.183673   0.518788     0.0   1.088309  ...   \n",
      "\n",
      "   dtype_object  dtype_datetime  dtype_bool                  filename  \\\n",
      "0             0               0           0  messy_001_titanic_v0.csv   \n",
      "1             0               0           0  messy_001_titanic_v0.csv   \n",
      "2             0               0           0  messy_001_titanic_v0.csv   \n",
      "3             0               0           0  messy_001_titanic_v0.csv   \n",
      "4             0               0           0  messy_001_titanic_v0.csv   \n",
      "\n",
      "   column_name  has_duplicates  has_missing  has_outliers  has_format_issue  \\\n",
      "0     survived               1            1             0                 1   \n",
      "1       pclass               1            1             0                 1   \n",
      "2          sex               1            1             0                 1   \n",
      "3          age               1            1             0                 1   \n",
      "4        sibsp               1            1             1                 1   \n",
      "\n",
      "   has_type_issue  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert to pandas DataFrame for easy analysis\n",
    "\"\"\"\n",
    "\n",
    "feature_df = pd.DataFrame(all_features)\n",
    "\n",
    "print(f\"Feature dataset shape: {feature_df.shape}\")\n",
    "print(f\"\\nColumns:\")\n",
    "print(feature_df.columns.tolist())\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(feature_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4329cab9-a461-411e-95d6-09dc1d60d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature dataset saved: ../data/processed/feature_dataset.csv\n",
      "   Shape: (129, 40)\n",
      "   Ready for ML training!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save for ML training\n",
    "\"\"\"\n",
    "\n",
    "output_path = '../data/processed/feature_dataset.csv'\n",
    "feature_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Feature dataset saved: {output_path}\")\n",
    "print(f\"   Shape: {feature_df.shape}\")\n",
    "print(f\"   Ready for ML training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6789de16-bf8f-4352-a92a-6ae5f9ff0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LABEL VERIFICATION\n",
      "============================================================\n",
      "\n",
      "has_duplicates:\n",
      "  Class 0:   18 ( 14.0%)\n",
      "  Class 1:  111 ( 86.0%)\n",
      "  ‚úÖ GOOD: Both classes present, 14.0% minority class\n",
      "\n",
      "has_missing:\n",
      "  Class 0:    6 (  4.7%)\n",
      "  Class 1:  123 ( 95.3%)\n",
      "  ‚ö†Ô∏è  IMBALANCED: Only 4.7% minority class\n",
      "\n",
      "has_outliers:\n",
      "  Class 0:   96 ( 74.4%)\n",
      "  Class 1:   33 ( 25.6%)\n",
      "  ‚úÖ GOOD: Both classes present, 25.6% minority class\n",
      "\n",
      "has_format_issue:\n",
      "  Class 0:   10 (  7.8%)\n",
      "  Class 1:  119 ( 92.2%)\n",
      "  ‚ö†Ô∏è  IMBALANCED: Only 7.8% minority class\n",
      "\n",
      "has_type_issue:\n",
      "  Class 0:  129 (100.0%)\n",
      "  Class 1:    0 (  0.0%)\n",
      "  ‚ùå STILL BROKEN: Only one class!\n",
      "\n",
      "============================================================\n",
      "If you see ‚úÖ GOOD for most problems, labels are fixed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Verify labels are properly distributed now\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìä LABEL VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for problem in ['has_duplicates', 'has_missing', 'has_outliers', 'has_format_issue', 'has_type_issue']:\n",
    "    counts = feature_df[problem].value_counts().sort_index()\n",
    "    total = len(feature_df)\n",
    "    \n",
    "    print(f\"\\n{problem}:\")\n",
    "    for class_val in [0, 1]:\n",
    "        count = counts.get(class_val, 0)\n",
    "        pct = (count / total) * 100\n",
    "        print(f\"  Class {class_val}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Check balance\n",
    "    if len(counts) == 1:\n",
    "        print(f\"  ‚ùå STILL BROKEN: Only one class!\")\n",
    "    elif len(counts) == 2:\n",
    "        minority_pct = (min(counts) / total) * 100\n",
    "        if minority_pct > 10:\n",
    "            print(f\"  ‚úÖ GOOD: Both classes present, {minority_pct:.1f}% minority class\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  IMBALANCED: Only {minority_pct:.1f}% minority class\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"If you see ‚úÖ GOOD for most problems, labels are fixed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300aec8-5fb1-42d9-b2f7-fd07cffeeeac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataclean)",
   "language": "python",
   "name": "dataclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
